# -*- coding: utf-8 -*-
"""Ricerca_operativa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MT-3ehhKicYVByMRS5oFXrpqDDtYI82S

# Elaborato di Ricerca Operativa: studio ed approfodnimento del MKP

Andrea Bedei, Fabio Notaro  
andrea.bedei2@studio.unibo.it, fabio.notaro2@studio.unibo.it

# Formulazione del problema:
Il problema del knapsack multidimensionale (zaino multidimensionale) è un problema dell'ottimizzazione combinatoria che coinvolge il riempimento di uno zaino con oggetti di diverse dimensioni e valori, rispettando i vincoli di capacità dello zaino.

La formulazione generale del problema del multidimensional knapsack è la seguente:

#Dati:


*   Un insieme di oggetti, ciascuno caratterizzato da un valore e da un vettore di dimensioni che rappresentano le diverse dimensioni degli oggetti.
*   Un vettore di capacità che indica i limiti massimi per ogni dimensione dello zaino.

#Obiettivo:
Massimizzare la somma dei valori degli oggetti nello zaino, rispettando i vincoli di capacità.

# Scrittura del modello matematico
* Sia $n$ il numero di oggetti.
* Sia $m$ il numero di dimensioni
* Sia $p$ un vettore di lunghezza $n$ contenente i profitti degli oggetti.
* Sia $W$ una matrice di pesi $n$ x $m$, dove $W_{ij}$ rappresenta il peso i-esimo dell'oggetto j-esimo
* Sia $c$ un vettore di lunghezza $m$ che rappresenta le capacità massime per ogni dimensione dello zaino
* Sia $x$ un vettore binario di variabili decisionali di lunghezza $n$, dove $x_j = 1$ se l'oggetto j-esimo è selezionato per essere messo nello zaino, altrimenti $x_j = 0$.

Lo scopo è massimizzare la seguente funzione obiettivo:

$$\max z =  \sum_{j=1}^{n} (p_j \cdot x_j)$$ 

$$s.t \sum_{j=1}^{n} (W_{ij} \cdot x_j) \leq c_i, \quad \text{per } i = 1, 2, \ldots, m$$

$$x_j \in \{0, 1\}, \quad \text{per } j = 1, 2, \ldots, n$$

Per evitare soluzioni banali si assume che :

* questa formulazione impone il vincolo che la somma delle dimensioni degli oggetti selezionati per lo zaino non superi le capacità massime in ogni dimensione $→ W_{ij} \leq c_i $ $∀i\in M, j\in N$ 

* il vettore x viene limitato a valori binari per indicare se l'oggetto corrispondente viene selezionato o meno

* $\sum_{j=1}^nW_{ij} > c_i $ $∀i\in M$.

# Idea di base per la soluzione
La soluzione al problema del multidimensional knapsack può essere ottenuta utilizzando una combinazione di algoritmi di programmazione dinamica e Branch and Bound.

In particolare:
* l'approccio di programmazione dinamica può essere utilizzato per risolvere un sotto-problema, noto come knapsack problem a una dimensione, per ciascuna dimensione dello zaino $→$ questo coinvolge la costruzione di una tabella che tiene traccia dei valori massimi ottenibili per ogni capacità della dimensione corrispondente
* successivamente, l'approccio di branch and bound può essere utilizzato per esplorare in modo efficiente lo spazio delle soluzioni, riducendo il numero di possibili soluzioni da considerare tramite tecniche di potatura dell'albero delle soluzioni.

# Teoria riguardante la soluzione del problema del knapsack multidimensionale attraverso la cooperazione tra programmazione dinamica e Branch and Bound

# Introduzione
I capitoli che seguono, in particolare, propongono una soluzione al problema del MKP esatta e cooperativa, che sfrutta l' utilizzo congiunto di euristiche di programmazione dinamica basate su un rilassamento surrogato e su una procedura di Branch and Bound.

In letteratura è stato dimostrato che l'utilizzo dei metodi cooperativi per la soluzione del classico KP ha portato ad un dimezzamento dei tempi computazionali rispetto all'utilizzo singolo degli algoritmi citati.

Data l'intrinseca difficolta del MKP, che ricordiamo essere un problema NP-hard, l'idea esplorata è quella di trasformare il problema originale in un classico Knapsack Problem.

Ciò ci permetterà dunque di trovare la soluzione ottima per MKP o comunque una sua approssimazione accettabile.

I numerosi metodi presentati in letteratura sono sostanzialmente derivati dai seguenti algoritmi:
* Branch and Bound consiste in una completa enumerazione, i cui bound sono usati per cercare tra i nodi quelli che non possono condurre alla soluzione ottima
* Dynamic programming può essere vista come un metodo di enumerazione breadth-first ma con l'aggiunta di tecniche di dominanza (che permettono di identificare le soluzioni "dominanti" all'interno di un insieme di soluzioni ammissibili).

# Metodo Branch and Bound

Come anticipato, l'algoritmo che andremo ad implementare si basa anche sull'algoritmo di Branch and Bound.

Il Branch and Bound appartiene  agli algoritmi di enumerazione, infatti utilizza procedure di bounding per ridurre le dimensioni dell’albero di ricerca. 

L’algoritmo calcola il bound di ogni nodo dell’albero ed identifica uno dei seguenti stati:
* se il bound indica che non può essere ottenuta una soluzione migliore della migliore soluzione ammissibile attualmente disponibile, il nodo viene eliminato
* invece, se il bound fornisce una soluzione ammissibile, si aggiorna la migliore soluzione ammissibile disponibile e il nodo viene eliminato
* altrimenti, se non si sono verificati i casi precedenti, il problema viene ulteriormente decomposto in 2 sottoproblemi (fase di branching) $→$ uno che esplora la situazione in cui l'oggetto corrente è inserito nello zaino ed un altro che esplora la situazione contraria, in cui cioè l'oggetto corrente non è stato inserito.

# Rilassamento surrogato

Il rilassamento surrogato del MKP può essere definito come segue:

$$S(u)= \max \sum_{j=1}^{n}(p_j ⋅ x_j) $$
$$s.t. \sum_{i=1}^{m}u_i ⋅ \sum_{j=1}^{n}W_{ij} ⋅ x_j \le \sum_{i=1}^{m}u_i ⋅ c_i$$
$$x_j \in \{0, 1\},∀j \in N$$

Sia adottata la seguente notazione: dato un problema $P$, indichiamo la sua soluzione ottima con $z^*$, mentre con $z_{UB}$ e $z_{LB}$ i valori di suoi upper e lower bound.

Siccome $S(u)$ è un rilassamento del MKP, si ha che $z_{S(u)}^* ≥ z_{MKP}^*$ e che $z_{S(u^*)}^* = min $ $z_{S(u)}^* : u\ge 0$.


Tuttavia, siccome risolvere l'equazione precedente è un problema NP-hard, una stima ragionevole dei moltiplicatori può essere calcolata attraverso la rimozione dei vincoli di interezza di $x$.

Quindi definiamo $LS(u)$ come il rilassamento continuo di $S(u)$:

$$LS(u)= \max \sum_{j=1}^{n}(p_j ⋅ x_j) $$
$$s.t. \sum_{i=1}^{m}u_i ⋅ \sum_{j=1}^{n}W_{ij} ⋅ x_j \le \sum_{i=1}^{m}u_i ⋅ c_i$$
$$x_j \in [0, 1],∀j \in N$$

I moltiplicatori surrogati ottimali continui possono essere derivati da $u^0$, che soddisfa l'uguaglianza $z_{LS(u^0)}^*=$ $ min $ $z_{LS(u)}^*$.

Per calcolare $u^0$, partiamo considerando il  problema di programmazione lineare (LP) corrispondente a MKP.

Denotiamo con $λ^0 = (λ_{1}^0,λ_{2}^0,...,λ_{m}^0,) ≥ 0$ le variabili duali ottimali associate al vincolo: $$ \sum_{j=1}^{n} W_{i,j} ⋅ x_j ≤ c_i, ∀j \in M  $$
Quindi i moltiplicatori continui ottimali surrogati possono essere ricavati attraverso l'equazione: $z_{S(u^*)}^* = min $ $z_{S(u)}^* : u\ge 0$ ed essi soddisfano la condizione $u^0 = λ^0$.

A questo punto abbiamo la seguente relazione di ordine:
$$z_{LP}^* = z_{LS(u^0)}^* ≥ z_{S(u^*)}^* ≥ z_{MKP}^* $$

# Programmazione dinamica ibrida

Denotiamo per semplicità:


*   $w_j$ rappresenta la  $\sum_{i=1}^{m} u_{i}^0 ⋅ W_{i,j}$
*   $c$ rappresenta la  $\sum_{i=1}^{m} u_{i}^0 ⋅ c_{i}$

A questo punto il problema diventa:
$$S(u^0)= \max \sum_{j=1}^{n}(p_j ⋅ x_j) $$
$$s.t. \sum_{j=1}^{n}W_{ij} ⋅ x_j \le c $$
$$x_j \in \{0, 1\},∀j \in N$$

Applichiamo l'algoritmo di programmazione dinamica a $S(u^0)$ e memorizziamo tutte le possibili soluzioni di MKP trovate.

Ad ogni passo $k \in N$ bisogna aggiornare una lista di coppie così definita:

$L_k = (w, p) : w=\sum_{i=1}^k (w_j ⋅ x_j) \le c,p=\sum_{i=1}^k (p_j ⋅ x_j)$

Gli stati vengono quindi ordinati nella lista in base al loro upper bound associato.

Sia $(w, p)$ lo stato generato al passo k dell'algoritmo. 

Possiamo definire il sottoproblema associato a $(w, p)$ come:

$$S(u^0)_{(w, p)}= \max \sum_{j=k+1}^{n}(p_j ⋅ x_j + p) $$
$$s.t. \sum_{j=k+1}^{n}w_j ⋅ x_j \le c-w$$
$$x_j \in \{0, 1\},j \in \{k+1..n\}$$

Dato uno stato $(w, p)$:
* un upper bound è ottenibile risolvendo il rilassamento lineare del problema sopra
* invece, un lower bound può essere ottenuto risolvendo il problema sopra con un algoritmo greedy.

# Implementazione MKP tramite programmazione dinamica ibrida
Nel presente capitolo è contenuta l'implementazione pratica degli algoritmi tramite le nozioni teoriche enunciate in precedenza.

Partiamo dalla definizione dell'istanza del problema:
"""

profittiOggetti = [10, 15, 20, 13] 
dimensioniOggetti = [[2, 3, 4], [1, 2, 3], [4, 5, 6], [3, 4, 5]]
dimensioniMassimeZaino = [7, 9, 11]

"""Proseguiamo definendo le dimensioni $N$ e $M$ del problema:"""

n = len(profittiOggetti)
m = len(dimensioniMassimeZaino)

"""Per calcolare una stima iniziale del valore ottimo, ossia un lower bound della soluzione, utilizzeremo un algoritmo Greedy che prevede di trovare i rapporti tra profitto e dimensione di ogni oggetto, in maniera del tutto analoga a quanto visto a lezione:"""

rapporti = [profittiOggetti[i] / sum(dimensioniOggetti[i]) for i in range(n)]

"""Calcoliamo una stima iniziale del valore ottimo utilizzando il concetto di rilassamento surrogato introdotto nella parte teorica e l'algoritmo Greedy.

In particolare, si calcola la somma dei prodotti tra le dimensioni rimanenti dello zaino e i rapporti profitto / dimensione degli oggetti rimanenti, ordinati in modo decrescente.

Successivamente, la funzione controlla se ogni oggetto può essere messo nello zaino e, se questo è vero, l'oggetto viene inserito, la sua contribuzione al valore ottimo viene aggiunta alla stima superiore e le dimensioni rimanenti dello zaino vengono ridotte di conseguenza. 

Se invece l'oggetto non può essere inserito, viene calcolato il valore massimo che si può ottenere utilizzando le dimensioni rimanenti dello zaino e gli oggetti rimanenti.

Questa stima viene utilizzata poi durante la ricerca in profondità (algoritmo Branch and Bound) per effettuare il pruning (cioè il taglio di stati non promettenti) in modo efficiente.
"""

dimensioni_rimaste = list(dimensioniMassimeZaino)
stima_superiore = 0
for rapporto, dimensioni_oggetto in sorted(zip(rapporti, dimensioniOggetti), reverse=True):
    if all(dimensione <= dimensione_rimasta for dimensione, dimensione_rimasta in zip(dimensioni_oggetto, dimensioni_rimaste)):
        stima_superiore += rapporto * sum(dimensioni_oggetto)
        dimensioni_rimaste = [dimensione_rimasta - dimensione for dimensione_rimasta, dimensione in zip(dimensioni_rimaste, dimensioni_oggetto)]
    else:
        stima_superiore += rapporto * sum(dimensione_rimasta * rapporto for dimensione_rimasta, rapporto in zip(dimensioni_rimaste, rapporti))
        break

"""Serve poi inizializzare la tabella per la programmazione dinamica, struttura dati fondamentale che permette di manetenere in ogni cella lo stato di un sottoproblema, evitando di risolverlo più volte:"""

tabella_pd = [[0] * (sum(dimensioniMassimeZaino) + 1) for _ in range(n + 1)]

"""Procediamo implementando la parte centrale dell'algoritmo di programmazione dinamica.

I due cicli innestati iterano su tutte le possibili sottoistanze del problema, ovvero studiano ogni combinazione di oggetti e di capacità dello zaino. 

All'inizio del ciclo, per ogni combinazione si copia il valore della cella precedente, che rappresenta la soluzione migliore ottenuta fino a quel punto.

Successivamente, si controlla se l'oggetto corrente può essere inserito nello zaino con la capacità corrente. 

Se ciò è possibile, si prende il valore della cella che rappresenta lo stato del problema considerando solo i precedenti oggetti e la capacità massima precedente e si somma al suo profitto.

Se questa soluzione è migliore di quella trovata fino a quel momento, allora si aggiorna il valore della cella corrente.

Alla fine, la soluzione ottima del problema globale sarà contenuta nell'ultima cella della tabella.
"""

for i in range(1, n + 1):
    for j in range(1, sum(dimensioniMassimeZaino) + 1):
        tabella_pd[i][j] = tabella_pd[i - 1][j]
        if all(dimensione <= j for dimensione in dimensioniOggetti[i - 1]):
            tabella_pd[i][j] = max(tabella_pd[i][j], tabella_pd[i - 1][j - sum(dimensioniOggetti[i - 1])] + profittiOggetti[i - 1])

"""
Serve poi inizializzare una pila, utilizzata per mantenere i nodi da visitare, ovvero quelli che sono stati scoperti ma non sono ancora stati esplorati. 

In pratica, durante l'esplorazione del grafo, ogni volta che l'algoritmo incontra un nuovo nodo da esplorare, questo viene inserito in cima alla pila:"""

stack = [(n, tuple(dimensioniMassimeZaino), 0, 0)]

"""Inizializziamo anche una variabile per memorizzare il valore della soluzione ottima:"""

soluzione_ottima = 0

"""Procediamo nell'algoritmo con la parte dedicata alla ricerca in profondità, utile a generare tutte le possibili combinazioni di oggetti da inserire nello zaino e a trovare la soluzione ottimale tra queste combinazioni.

L'algoritmo parte dallo stato iniziale (nessun oggetto inserito nello zaino) e genera tutti i possibili successori di questo stato, ovvero tutte le possibili combinazioni di oggetti da inserire o da escludere dallo zaino. 

Per ogni successore generato, l'algoritmo calcola il suo valore (ovvero il profitto totale degli oggetti inseriti nello zaino) e lo confronta con il valore della soluzione ottimale finora trovata: se il valore del successore è maggiore, allora il successore diventa lo stato corrente dell'algoritmo e la ricerca continua a partire da questo nuovo stato. 

Se invece il valore del successore è minore o uguale al valore della soluzione ottimale, allora l'algoritmo abbandona il successore e cerca altri possibili successori.

In questo modo, l'algoritmo visita tutte le possibili combinazioni di oggetti da inserire nello zaino, eliminando i rami dell'albero di ricerca che non portano a soluzioni migliori di quella già trovata, fino a trovare la soluzione ottimale.

Il codice seguente implementa l'algoritmo di branching. 

Esso combina lo spazio delle soluzioni e l'idea del "bounding" (vincolo) per eliminare sottoinsiemi di soluzioni non promettenti.
"""

while stack:
    i, dimensioni_rimaste, valore, peso = stack.pop()
    # Verifica se il peso corrente supera la somma delle dimensioni massime dello zaino.
    if peso > sum(dimensioniMassimeZaino):
        continue
    # Verifica se la somma del valore corrente e una stima superiore è inferiore alla soluzione ottima finora trovata.
    if valore + stima_superiore < soluzione_ottima:
        continue
    #  Verifica se si è arrivati all'ultimo elemento da considerare. In tal caso si controlla se il valore corrente supera la soluzione ottima finora trovata.
    if i == 0:
        soluzione_ottima = max(soluzione_ottima, valore)
        continue
    # Verifica se tutte le dimensioni dell'oggetto corrente sono <= alle dimensioni rimanenti dello zaino.
    if all(dimensione <= dimensione_rimasta for dimensione, dimensione_rimasta in zip(dimensioniOggetti[i - 1], dimensioni_rimaste)):
        # Crea uno stato in cui l'oggetto corrente è inserito nello zaino.
        stack.append((i - 1, tuple(dimensione_rimasta - dimensione for dimensione_rimasta, dimensione in zip(dimensioni_rimaste, dimensioniOggetti[i - 1])), valore + profittiOggetti[i - 1], peso + sum(dimensioniOggetti[i - 1])))
    # Cioè viene utilizzata per eliminare i rami dell'albero di ricerca che non portano a una soluzione ottima.
    # Se il valore corrente più una stima superiore del valore rimanente (stima_superiore) è minore della soluzione ottima trovata finora, allora si può interrompere l'esplorazione di quel ramo.
    if tabella_pd[i - 1][peso] + valore + stima_superiore - tabella_pd[i][peso] < soluzione_ottima:
        continue
    # Creo uno stato in cui l'oggetto corrente non è inserito nello zaino.
    stack.append((i - 1, dimensioni_rimaste, valore, peso))

"""Finalemente è possibile visualizzare il valore della soluzione ottima troavata:"""

print(soluzione_ottima)

"""# Soluzione del problema utilizzando il solver pulp
Per valutare la correttezza della soluzione dell'algoritmo, facciamo calcolare la soluzione del problema anche a un solver commerciale:
"""

!pip install pulp
from pulp import *

def knapsack_multidimensional(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino):
    n = len(profittiOggetti) 
    m = len(dimensioniMassimeZaino) 

    # Definiamo il problema di ottimizzazione come problema di massimizzazione.
    prob = LpProblem("Knapsack Multidimensionale", LpMaximize)

    # Definiamo le variabili decisionali, una per ogni oggetto.
    x = [LpVariable(f"x{i}", lowBound=0, cat="Integer", upBound=1) for i in range(n)]

    # Definiamo la funzione obiettivo.
    prob += lpSum([profittiOggetti[i] * x[i] for i in range(n)])

    # Definiamo i vincoli di capacità per ciascuna dimensione dello zaino.
    for j in range(m):
        prob += lpSum([dimensioniOggetti[i][j] * x[i] for i in range(n)]) <= dimensioniMassimeZaino[j]

    # Risoluzione del problema.
    prob.solve()

    # Verifica dell'ottimalità della soluzione inviduata.
    if prob.status != LpStatusOptimal:
        return None

    soluzione = []
    for i in range(n):
        soluzione.append(int(value(x[i])))

    z = sum([profittiOggetti[i] * soluzione[i] for i in range(n)])

    return soluzione, z

print(knapsack_multidimensional(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino))

"""Come si nota, la soluzione del solver equivale a quella dell'algoritmo ibrido da noi studiato, indicandone la correttezza.

La complessità computazionale del nostro codice dipende dal metodo utilizzato per calcolare la stima iniziale del valore ottimo, ma è dell'ordine di $O(nW log n)$, dove $n$ è il numero di oggetti e $W$ è la somma delle dimensioni massime dello zaino.

In particolare, la parte della funzione che utilizza la programmazione dinamica per calcolare la tabella dei valori ha complessità $O(nW)$, poiché deve esaminare tutti i sottoinsiemi possibili di oggetti e per ciascuno di essi deve calcolare il valore massimo che può essere ottenuto.

# Confronto tra le performance dei due algoritmi

Per comodità creiamo la funzione per la risoluzione del problema tramite programmazione dinamica ibrida:
"""

def MKP_Programmazione_dinamica_ibrida(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino, stampa=False):
    n = len(profittiOggetti)
    m = len(dimensioniMassimeZaino)
    rapporti = [profittiOggetti[i] / sum(dimensioniOggetti[i]) for i in range(n)]
    dimensioni_rimaste = list(dimensioniMassimeZaino)
    stima_superiore = 0
    
    for rapporto, dimensioni_oggetto in sorted(zip(rapporti, dimensioniOggetti), reverse=True):
        if all(dimensione <= dimensione_rimasta for dimensione, dimensione_rimasta in zip(dimensioni_oggetto, dimensioni_rimaste)):
            stima_superiore += rapporto * sum(dimensioni_oggetto)
            dimensioni_rimaste = [dimensione_rimasta - dimensione for dimensione_rimasta, dimensione in zip(dimensioni_rimaste, dimensioni_oggetto)]
        else:
            stima_superiore += rapporto * sum(dimensione_rimasta * rapporto for dimensione_rimasta, rapporto in zip(dimensioni_rimaste, rapporti))
            break
    tabella_pd = [[0] * (sum(dimensioniMassimeZaino) + 1) for _ in range(n + 1)]
    for i in range(1, n + 1):
        for j in range(1, sum(dimensioniMassimeZaino) + 1):
            tabella_pd[i][j] = tabella_pd[i - 1][j]
            if all(dimensione <= j for dimensione in dimensioniOggetti[i - 1]):
                tabella_pd[i][j] = max(tabella_pd[i][j], tabella_pd[i - 1][j - sum(dimensioniOggetti[i - 1])] + profittiOggetti[i - 1])
    stack = [(n, tuple(dimensioniMassimeZaino), 0, 0)]
    soluzione_ottima = 0
    while stack:
        i, dimensioni_rimaste, valore, peso = stack.pop()
        if peso > sum(dimensioniMassimeZaino):
            continue
        if valore + stima_superiore < soluzione_ottima:
            continue
        if i == 0:
            if stampa and soluzione_ottima!=max(soluzione_ottima, valore):
                print(soluzione_ottima)
            soluzione_ottima = max(soluzione_ottima, valore)
            continue
        if all(dimensione <= dimensione_rimasta for dimensione, dimensione_rimasta in zip(dimensioniOggetti[i - 1], dimensioni_rimaste)):
            stack.append((i - 1, tuple(dimensione_rimasta - dimensione for dimensione_rimasta, dimensione in zip(dimensioni_rimaste, dimensioniOggetti[i - 1])), valore + profittiOggetti[i - 1], peso + sum(dimensioniOggetti[i - 1])))
        if tabella_pd[i - 1][peso] + valore + stima_superiore - tabella_pd[i][peso] < soluzione_ottima:
            continue
        stack.append((i - 1, dimensioni_rimaste, valore, peso))
    return soluzione_ottima

"""Creiamo un'istanza un po' più complessa per confrontare i tempi di elaborazione dei due algoritmi."""

import random
numOggetti = 23
dimensioniMassimeZaino = [511, 213, 777]
dimensioniMassime = [int(dimensioniMassimeZaino[0]/5), int(dimensioniMassimeZaino[1]/5), int(dimensioniMassimeZaino[2]/5)]

random.seed(123)
profittiOggetti = []
dimensioniOggetti = []

for i in range(numOggetti):
    profitto = random.randint(100, 500)
    dimensioni = [random.randint(0, dimensioniMassime[0]), random.randint(0, dimensioniMassime[1]), random.randint(0, dimensioniMassime[2])]
    profittiOggetti.append(profitto)
    dimensioniOggetti.append(dimensioni)

"""Richiamiamo la nostra funzione e calcoliamo il tempo di esecuzione:"""

import time

start_time = time.time()
print(MKP_Programmazione_dinamica_ibrida(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino))
end_time = time.time()
execution_time = end_time - start_time
print("Tempo di esecuzione algoritmo (time):", execution_time, "secondi")

"""Ora calcoliamo il tempo di esecuzione attraverso l'uso del solver:"""

start_time = time.time()
print(knapsack_multidimensional(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino))
end_time = time.time()
execution_time = end_time - start_time
print("Tempo di esecuzione solver (time):", execution_time, "secondi")

"""Come si nota ed era prevedibile immaginare, il solver è estremamente più rapido rispetto al nostro algoritmo.

#Limiti dell'algoritmo ibrido
Basta aggiungere pochi oggetti alla stessa istanza usata nel precedente esperimento affinchè l'algoritmo ibrido non riesca a convergere in un tempo ragionevole, obbligandoci a interromperlo prematuramente (cosa che non accade col solver).
"""

numOggetti = 30
dimensioniMassimeZaino = [511, 213, 777]
dimensioniMassime = [int(dimensioniMassimeZaino[0]/5), int(dimensioniMassimeZaino[1]/5), int(dimensioniMassimeZaino[2]/5)]

random.seed(123)
profittiOggetti = []
dimensioniOggetti = []

for i in range(numOggetti):
    profitto = random.randint(100, 500)
    dimensioni = [random.randint(0, dimensioniMassime[0]), random.randint(0, dimensioniMassime[1]), random.randint(0, dimensioniMassime[2])]
    profittiOggetti.append(profitto)
    dimensioniOggetti.append(dimensioni)

start_time = time.time()
print(knapsack_multidimensional(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino))
end_time = time.time()
execution_time = end_time - start_time
print("Tempo di esecuzione solver (time):", execution_time, "secondi")

start_time = time.time()
print(MKP_Programmazione_dinamica_ibrida(profittiOggetti, dimensioniOggetti, dimensioniMassimeZaino, True))
end_time = time.time()
execution_time = end_time - start_time
print("Tempo di esecuzione algoritmo (time):", execution_time, "secondi")

"""Come si nota a seguito dell'interruzione esiste un gap tra la soluzione ottima trovata dal solver e la migliore soluzione trovata dall'algoritmo di programmazione dinamica ibrida. 

In base al numero di oggetti e alle loro dimensoni aumenta infatti la complessità computazionale del problema, quindi anche il tempo di convergenza alla soluzione ottima. 

Occorre dunque individuare il migliore trade off tra il tempo di elaborazione che è possibile investire e l'accuratezza della soluzione desiderata.

# Conclusioni
Dividiamo le conclusioni in due parti: la prima approfondirà le considerazioni finali circa l'algoritmo sviluppato, mentre la seconda si concentrerà maggiormente sull'elaborato. 

Per quanto concerne l'algoritmo sviluppato, come riportato anche nel materiale approfondito, emerge che il principale vantaggio della programmazione dinamica ibrida mista al metodo Branch and Bound è che ci permette di ottenere buone performance in termini di gap rispetto alla soluzione ottima e tutto sommato anche in termini di tempo di elaborazione. 

In particolare, la cooperazione e l'uso congiunto di BB e DP ci permette di ottenere un buon metodo in grado di trovare la soluzione ottima o una approssimazione accettabile nel caso di arresto anticipato.

Per quanto invece riguarda le conclusioni complessive circa il presente elaborato, ci riteniamo soddisfatti del lavoro svolto e delle conoscenza acquisite su un problema di nostro interesse.

Riteniamo dunque positiva e stimolante la possibilità offerta di poter esplorare ed approfondire da un punto di vista più pratico le nozioni teoriche affrontate a lezione.
"""